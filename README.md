# SHRI-2018-homework-11

### Домашняя работа по теме "Алгоритмы"

Яндекс. Школа разработки интерфейсов. 2018 год.

#### Задание 1: emitter

Ссылка для просмотра [страницы](https://alivander.github.io/SHRI-2018-homework-11/source/emitter.html)  
  
При большом количестве событий, самая дорогая операция, это удаление (отписка) обработчиков из очереди для события. Если использовать традиционный массив, то при отписке придется перезаписывать весь массив. Поэтому для очереди обработчиков я использовала Map. Так как он не завязан на строгом порядке элементов, то при удалении обработчиков из очереди не перестраивает всю остальную очередь, при этом сохраняя порядок элементов, в котором они были добавлены. А значит при генерации события и вызове обработчиков их порядок не измениться.   
Так как в нашем случае обработчик по факту всего один и ему равен любой из обработчиков в очереди, то удаление из очереди получается не совсем честным. На самом деле в нашем частном случае проверка обработчика в следующем выражении не имеет смысла:  
```
for (const [key, value] of queue.entries()) {  
    if (value === handler) {  
        queue.delete(key); 
        break;  
    }  
}
```  
И в любом случае из-за совпадения обработчиков они начинают удаляться из начала очереди. Это можно попробовать обойти каким-то генератором обработчиков, который будет создавать их уникальными, а потом сохранять в отдельную переменную, чтобы сравнивать при отписке... но это, кажется, уже никак не относится к заданию)).  
Но, так как удаление из начала и является самым долгим и тяжелым, то нам для демонстрации такое поведение подходит.  
Я честно не знаю укладывается ли это в понятие "работа с алгоритмами") Можно было бы конечно создать какой-то самописный аналог Map, но, как бы, зачем, если это уже есть в самом языке. 


#### Задание 2: saggest

Ссылка для просмотра [страницы](https://alivander.github.io/SHRI-2018-homework-11/source/saggest.html)  
  
Для оптимизации взаимодействия с пользователем вызов saggest в коде происходит с timeout в 250ms, чтобы поиск не начинался при нажатии каждой клавиши, если человек еще не допечатал строку. Это время не входит в расчет времени работы функции. При необходимости его можно убрать.  
  
Для начала для поиска подстроки я попробовала использовать выражение:  
```
for (const street of streets) {
    ...
  street.match(new RegExp(substr, 'i'));
```
Для подстроки "теат" результат выдавался в среднем через 100-120 ms.  
Это слишком долго) Я попробовала другой метод:  
```
substr = substr.toLowerCase();

for (const street of streets) {
    ...
    street.toLowerCase().includes(substr);

```
Этот способ для той же подстроки выдавал результат за 5-8 ms.  

Я знаю, что половина группы использовала для оптимизации поиска суффиксные деревья(хеш-таблицы), поэтому я не стала их использовать)). Как они работают мне понятно, но у задачи не может одного решения, и мне было интересно найти свое.  
  
Для оптимизации поиска я попробовала разбить массив данных на отдельные кластеры и осуществлять по ним асинхронный поиск с одним общим счетчиком результатов. Когда найдено 10 подходящих строк, обход кластеров заканчивается, результаты собираются во фрагмент (document.fragment) и вставляются на страницу не по одному, а целым списком.  
Для усложнения поиска база улиц была продублирована 3 раза. Поэтому в выдаваемых результатах названия улиц могут повторяться, это не ошибка. Но все же, так как время выполнения уже очень мало, то погрешность большая и при поиске подстроки очень сложно понять уменьшилось ли время выполнения благодаря кластерам или нет - цифры скачут и очень разнятся. Но при поиске несуществующей строки (в данном случае это любая строка c латиницей), то есть в ситуации когда происходит полный обход всего массива, поиск по кластерам выдает лучшие результаты.  
Конечно, такой способ на самом деле должен задействовать сервер - данные должны быть разбиты на кластеры заранее и уже в таком виде отдаваться на клиент, иначе этот метод будет задействовать 2N памяти из-за дублирования данных.  
  
  
Сложность и в первом задании О(N), так как по сути просто идет перебор очереди. Во втором - O(N * M), где M - количество кластеров.
